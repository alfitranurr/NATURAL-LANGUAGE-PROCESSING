{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Reddit data collection...\n",
      "Processing post 1 - Current data count: 0\n",
      "Processing post 2 - Current data count: 493\n",
      "Processing post 3 - Current data count: 984\n",
      "Processing post 4 - Current data count: 1479\n",
      "Processing post 5 - Current data count: 1973\n",
      "Processing post 6 - Current data count: 2467\n",
      "Processing post 7 - Current data count: 2953\n",
      "Processing post 8 - Current data count: 3445\n",
      "Processing post 9 - Current data count: 3935\n",
      "Processing post 10 - Current data count: 4430\n",
      "Processing post 11 - Current data count: 4920\n",
      "Processing post 12 - Current data count: 5408\n",
      "Processing post 13 - Current data count: 5898\n",
      "Processing post 14 - Current data count: 6386\n",
      "Processing post 15 - Current data count: 6879\n",
      "Processing post 16 - Current data count: 7364\n",
      "Processing post 17 - Current data count: 7856\n",
      "Processing post 18 - Current data count: 8351\n",
      "Processing post 19 - Current data count: 8839\n",
      "Processing post 20 - Current data count: 9332\n",
      "Processing post 21 - Current data count: 9825\n",
      "Saving data to files...\n",
      "Data collection completed!\n",
      "Total data collected: 10000\n",
      "Execution time: 3.02 minutes\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Reddit API credentials\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "\n",
    "# Inisialisasi Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")\n",
    "\n",
    "# Subreddit yang akan di-scrape\n",
    "subreddits = ['politics']\n",
    "\n",
    "# Definisi rentang tanggal\n",
    "START_DATE = datetime(2019, 1, 1).timestamp()  # 1 Januari 2019\n",
    "END_DATE = datetime(2025, 3, 21).timestamp()  # 21 Maret 2025\n",
    "\n",
    "# Fungsi untuk mengumpulkan data\n",
    "def collect_reddit_data(target_count=10000):\n",
    "    data = []\n",
    "    posts_processed = 0\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        \n",
    "        # Mengambil post dari kategori \"top\" sepanjang waktu\n",
    "        for submission in subreddit.top(time_filter=\"all\", limit=None):\n",
    "            # Filter berdasarkan timestamp postingan\n",
    "            submission_timestamp = submission.created_utc\n",
    "            if not (START_DATE <= submission_timestamp <= END_DATE):\n",
    "                posts_processed += 1\n",
    "                print(f\"Skipping post {posts_processed} - Outside date range: {datetime.fromtimestamp(submission_timestamp)}\")\n",
    "                continue\n",
    "                \n",
    "            if len(data) >= target_count:\n",
    "                break\n",
    "                \n",
    "            posts_processed += 1\n",
    "            print(f\"Processing post {posts_processed} - Current data count: {len(data)}\")\n",
    "            \n",
    "            # Memastikan semua komentar dimuat\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            \n",
    "            # Menggunakan permalink Reddit sebagai Content_Link\n",
    "            content_link = f\"https://www.reddit.com{submission.permalink}\"\n",
    "            \n",
    "            for comment in submission.comments.list():\n",
    "                if len(data) >= target_count:\n",
    "                    break\n",
    "                    \n",
    "                # Filter komentar berdasarkan timestamp\n",
    "                comment_timestamp = comment.created_utc\n",
    "                if not (START_DATE <= comment_timestamp <= END_DATE):\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    comment_data = {\n",
    "                        'Subreddit': subreddit_name,\n",
    "                        'Post_Title': submission.title,\n",
    "                        'Username': comment.author.name if comment.author else '[deleted]',\n",
    "                        'Comment': comment.body,\n",
    "                        'Score': comment.score,\n",
    "                        'Content_Link': content_link,\n",
    "                        'Timestamp': datetime.fromtimestamp(comment_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    }\n",
    "                    data.append(comment_data)\n",
    "                    \n",
    "                except AttributeError as e:\n",
    "                    print(f\"Error processing comment: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Delay untuk menghindari rate limit\n",
    "            time.sleep(1)\n",
    "            \n",
    "        if len(data) >= target_count:\n",
    "            break\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Fungsi untuk menyimpan ke TXT\n",
    "def save_to_txt(data, filename=\"reddit_data.txt\"):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(f\"Subreddit: {item['Subreddit']}\\n\")\n",
    "            f.write(f\"Post Title: {item['Post_Title']}\\n\")\n",
    "            f.write(f\"Username: {item['Username']}\\n\")\n",
    "            f.write(f\"Comment: {item['Comment']}\\n\")\n",
    "            f.write(f\"Score: {item['Score']}\\n\")\n",
    "            f.write(f\"Content Link: {item['Content_Link']}\\n\")\n",
    "            f.write(f\"Timestamp: {item['Timestamp']}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Fungsi untuk menyimpan ke CSV\n",
    "def save_to_csv(data, filename=\"reddit_data.csv\"):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    print(\"Starting Reddit data collection...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Mengumpulkan data\n",
    "    collected_data = collect_reddit_data()\n",
    "    \n",
    "    # Menyimpan data\n",
    "    print(\"Saving data to files...\")\n",
    "    save_to_txt(collected_data)\n",
    "    save_to_csv(collected_data)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) / 60  # dalam menit\n",
    "    \n",
    "    print(f\"Data collection completed!\")\n",
    "    print(f\"Total data collected: {len(collected_data)}\")\n",
    "    print(f\"Execution time: {execution_time:.2f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deteksi Subreddit Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai deteksi data unik di kolom Subreddit...\n",
      "Data Unik di Kolom Subreddit:\n",
      "------------------------------\n",
      "politics\n",
      "------------------------------\n",
      "Total jumlah subreddit unik: 1\n",
      "Proses selesai!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fungsi untuk mendeteksi data unik di kolom Subreddit\n",
    "def detect_unique_subreddits(csv_file=\"reddit_data.csv\"):\n",
    "    try:\n",
    "        # Membaca file CSV\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Mengekstrak nilai unik dari kolom 'Subreddit'\n",
    "        unique_subreddits = df['Subreddit'].unique()\n",
    "        \n",
    "        # Menampilkan hasil\n",
    "        print(\"Data Unik di Kolom Subreddit:\")\n",
    "        print(\"-\" * 30)\n",
    "        for subreddit in unique_subreddits:\n",
    "            print(subreddit)\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Total jumlah subreddit unik: {len(unique_subreddits)}\")\n",
    "        \n",
    "        return unique_subreddits\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {csv_file} tidak ditemukan. Pastikan file sudah ada.\")\n",
    "        return None\n",
    "    except KeyError:\n",
    "        print(\"Kolom 'Subreddit' tidak ditemukan di file CSV.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi kesalahan: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    print(\"Memulai deteksi data unik di kolom Subreddit...\")\n",
    "    unique_subreddits = detect_unique_subreddits()\n",
    "    \n",
    "    if unique_subreddits is not None:\n",
    "        print(\"Proses selesai!\")\n",
    "    else:\n",
    "        print(\"Proses gagal.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rentang Tanggal Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menampilkan tanggal unik dari reddit_data.csv...\n",
      "Total tanggal unik: 63\n",
      "Daftar tanggal unik:\n",
      "2019-12-19\n",
      "2020-03-17\n",
      "2020-03-18\n",
      "2020-03-30\n",
      "2020-04-11\n",
      "2020-04-13\n",
      "2020-04-14\n",
      "2020-04-18\n",
      "2020-06-03\n",
      "2020-06-04\n",
      "2020-06-09\n",
      "2020-06-12\n",
      "2020-06-13\n",
      "2020-06-14\n",
      "2020-06-15\n",
      "2020-06-16\n",
      "2020-06-17\n",
      "2020-06-18\n",
      "2020-06-19\n",
      "2020-06-25\n",
      "2020-06-26\n",
      "2020-07-08\n",
      "2020-07-17\n",
      "2020-07-31\n",
      "2020-08-01\n",
      "2020-08-11\n",
      "2020-08-13\n",
      "2020-08-15\n",
      "2020-08-21\n",
      "2020-10-17\n",
      "2020-10-18\n",
      "2020-11-06\n",
      "2020-11-07\n",
      "2020-11-08\n",
      "2020-11-12\n",
      "2020-11-13\n",
      "2021-01-06\n",
      "2021-01-07\n",
      "2021-01-11\n",
      "2021-01-12\n",
      "2021-01-14\n",
      "2021-01-20\n",
      "2021-01-21\n",
      "2021-01-22\n",
      "2021-01-25\n",
      "2021-01-26\n",
      "2021-01-29\n",
      "2021-01-30\n",
      "2021-03-26\n",
      "2021-03-27\n",
      "2021-05-01\n",
      "2021-05-02\n",
      "2021-05-03\n",
      "2021-05-04\n",
      "2021-05-13\n",
      "2021-05-17\n",
      "2021-05-22\n",
      "2021-05-25\n",
      "2021-05-26\n",
      "2021-06-19\n",
      "2022-02-28\n",
      "2022-03-01\n",
      "2022-03-06\n",
      "\n",
      "Proses selesai!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Fungsi untuk membaca data dari CSV dan mendapatkan tanggal unik\n",
    "def get_unique_dates(filename=\"reddit_data.csv\"):\n",
    "    try:\n",
    "        # Membaca file CSV ke DataFrame\n",
    "        df = pd.read_csv(filename, encoding='utf-8')\n",
    "        \n",
    "        # Pastikan kolom 'Timestamp' ada\n",
    "        if 'Timestamp' not in df.columns:\n",
    "            print(\"Error: Kolom 'Timestamp' tidak ditemukan dalam file CSV.\")\n",
    "            return\n",
    "        \n",
    "        # Konversi kolom 'Timestamp' ke datetime dan ekstrak hanya tanggal (YYYY-MM-DD)\n",
    "        df['Date'] = pd.to_datetime(df['Timestamp']).dt.date\n",
    "        \n",
    "        # Dapatkan tanggal unik\n",
    "        unique_dates = sorted(df['Date'].unique())\n",
    "        \n",
    "        # Tampilkan hasil\n",
    "        print(f\"Total tanggal unik: {len(unique_dates)}\")\n",
    "        print(\"Daftar tanggal unik:\")\n",
    "        for date in unique_dates:\n",
    "            print(date)\n",
    "            \n",
    "        return unique_dates\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' tidak ditemukan.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Terjadi kesalahan - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    print(\"Menampilkan tanggal unik dari reddit_data.csv...\")\n",
    "    unique_dates = get_unique_dates()\n",
    "    \n",
    "    if unique_dates:\n",
    "        print(\"\\nProses selesai!\")\n",
    "    else:\n",
    "        print(\"\\nProses gagal.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
